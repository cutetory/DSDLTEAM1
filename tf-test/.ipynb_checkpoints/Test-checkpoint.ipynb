{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f193c7d7-b80d-4a0d-a788-84e8aea87b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작성자 박준영\n"
     ]
    }
   ],
   "source": [
    "print(\"작성자 박준영\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387c9790-809b-4018-bb5a-2fc7fdfa6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ddddddddd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"안녕하세욤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b39e9f-afab-4135-8fa2-20689b59e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a7a48-7d18-4ef2-85fe-9d6f9cc8221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"안녕하세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e41672-b0b3-4ac5-ab15-a3d28be47744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4148544e-af57-4dba-b16e-b8b955204f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 04:57:02.589684: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-13 04:57:02.723344: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 04:57:04.567724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:04.581275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:04.581464: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:04.583963: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:04.584095: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:04.584212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:05.296213: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:05.296483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:05.296500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-13 04:57:05.296612: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-13 04:57:05.296646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21579 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 설정 완료\n",
      "첫 번째 실행 (GPU 초기화)\n",
      "100 번의 연산을 수행하며 GPU 성능 테스트를 진행합니다.\n",
      "100 번의 연산을 완료하는 데 걸린 총 시간: 0.01 초\n",
      "한 번의 연산 평균 소요 시간: 0.0001 초\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "\n",
    "# GPU 사용 설정\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"GPU 설정 완료\")\n",
    "else:\n",
    "    print(\"GPU를 찾을 수 없습니다. CPU\")\n",
    "\n",
    "# 테스트할 데이터 생성\n",
    "input_data = tf.random.normal((10000, 1000))\n",
    "\n",
    "# 모델 정의 (간단한 덧셈 연산)\n",
    "def simple_model(input_data):\n",
    "    return tf.reduce_sum(input_data)\n",
    "\n",
    "# 첫 번째 실행 (GPU 초기화 등)\n",
    "print(\"첫 번째 실행 (GPU 초기화)\")\n",
    "with tf.device('/GPU:0'):\n",
    "    _ = simple_model(input_data)\n",
    "\n",
    "# 성능 테스트 시작\n",
    "num_iterations = 100\n",
    "\n",
    "print(f\"{num_iterations} 번의 연산을 수행하며 GPU 성능 테스트를 진행합니다.\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    with tf.device('/GPU:0'):\n",
    "        _ = simple_model(input_data)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"{num_iterations} 번의 연산을 완료하는 데 걸린 총 시간: {elapsed_time:.2f} 초\")\n",
    "print(f\"한 번의 연산 평균 소요 시간: {elapsed_time / num_iterations:.4f} 초\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
