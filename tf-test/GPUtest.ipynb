{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:37.395689: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-14 15:17:37.418691: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:Python Î≤ÑÏ†Ñüìå sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:Pytorch Î≤ÑÏ†Ñüìå 2.0.1+cu117\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:torchvision Î≤ÑÏ†Ñüìå 0.15.2+cu117\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:ninja Î≤ÑÏ†Ñüìå 1.11.1\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:Torch GPU Í∞ÄÎä•Ïó¨Î∂Äüìå True\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:Tensorflow GPU Í∞ÄÎä•Ïó¨Î∂Äüìå [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-08-14 15:17:38: [/tmp/ipykernel_809/3217722870.py]:Click Versionüìå 8.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:38.448767: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:38.449456: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:38.449579: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import inspect #ÎîîÎ≤ÑÍπÖÏö©\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import ninja\n",
    "import click\n",
    "\n",
    "def time_stamp():\n",
    "    temp = r\"%Y-%m-%d %H:%M:%S\"\n",
    "    current_frame = inspect.currentframe()\n",
    "    tmp = f\"{time.strftime(temp, time.localtime(time.time()))}: [{inspect.getframeinfo(current_frame).filename}]:\"\n",
    "    return tmp\n",
    "\n",
    "def version_all():\n",
    "    print(f\"{time_stamp()}Python Î≤ÑÏ†Ñüìå {sys.version_info}\")\n",
    "    print(f\"{time_stamp()}Pytorch Î≤ÑÏ†Ñüìå {torch.__version__}\")\n",
    "    print(f\"{time_stamp()}torchvision Î≤ÑÏ†Ñüìå {torchvision.__version__}\")\n",
    "    print(f\"{time_stamp()}ninja Î≤ÑÏ†Ñüìå {ninja.__version__}\")\n",
    "    print(f\"{time_stamp()}Tensorflow Î≤ÑÏ†Ñüìå {tf.__version__}\")\n",
    "    print(f\"{time_stamp()}Torch GPU Í∞ÄÎä•Ïó¨Î∂Äüìå {torch.torch.cuda.is_available()}\")\n",
    "    print(f\"{time_stamp()}Tensorflow GPU Í∞ÄÎä•Ïó¨Î∂Äüìå {tf.config.list_physical_devices('GPU')}\") # ÌÖêÏÑúÌîåÎ°úÏö∞ 2.xÎ≤ÑÏ†Ñ\n",
    "    # print(f\"{time_stamp()}Tensorflow GPU Í∞ÄÎä•Ïó¨Î∂Äüìå {device_lib.list_local_devices()}\") # ÌÖêÏÑúÌîåÎ°úÏö∞ 1.xÎ≤ÑÏ†Ñ\n",
    "    print(f\"{time_stamp()}Click Versionüìå {click.__version__}\") # ÌÖêÏÑúÌîåÎ°úÏö∞ 1.xÎ≤ÑÏ†Ñ\n",
    "    # print(f\"{time_stamp()}Click Versionüìå {cudatoolkit.__version__}\")\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "version_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU says hello.\n",
      "GPU says hello.\n"
     ]
    }
   ],
   "source": [
    "!nvcc test_nvcc.cu -o test_nvcc -run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow ÏÑ∏ÏÖò ÎòêÎäî Í∑∏ÎûòÌîÑÍ∞Ä Ï¢ÖÎ£åÎêú ÌõÑÏóê Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# GPU Î©îÎ™®Î¶¨ Ï†úÌïú ÏÑ§Ï†ï\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=20480)]  # 4GB Î©îÎ™®Î¶¨ Ìï†Îãπ\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÖåÏä§Ìä∏Ìï† Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±\n",
    "# import pandas as pd\n",
    "# input_data = tf.random.normal((10000, 1000))\n",
    "# print(f\"Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± ÏôÑÎ£å: {input_data.shape}\")\n",
    "# before_df = pd.DataFrame(input_data)\n",
    "# before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "try:\n",
    "    from matplotlib import pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'matplotlib'])\n",
    "    try:\n",
    "        from matplotlib import pyplot as plt\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'numpy'])\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î•º Îñ†Î®πÏó¨ Ï§Ñ ÌÅ¥ÎûòÏä§Î•º Ï†úÏûëÌï©ÎãàÎã§.\n",
    "class DataReader:\n",
    "    def __init__(self):\n",
    "        self.label_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "        self.mnist = keras.datasets.mnist\n",
    "        (train_X, self.train_Y), (test_X, self.test_Y) = self.mnist.load_data()\n",
    "\n",
    "        self.train_X = np.asarray(train_X) / 255.0\n",
    "        self.test_X = np.asarray(test_X) / 255.0\n",
    "\n",
    "        # Îç∞Ïù¥ÌÑ∞ ÏùΩÍ∏∞Í∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\n",
    "        # ÏùΩÏñ¥Ïò® Îç∞Ïù¥ÌÑ∞Ïùò Ï†ïÎ≥¥Î•º Ï∂úÎ†•Ìï©ÎãàÎã§.\n",
    "        print(\"\\n\\nData Read Done!\")\n",
    "        print(\"Training X Size : \" + str(self.train_X.shape))\n",
    "        print(\"Training Y Size : \" + str(self.train_Y.shape))\n",
    "        print(\"Test X Size : \" + str(self.test_X.shape))\n",
    "        print(\"Test Y Size : \" + str(self.test_Y.shape) + '\\n\\n')\n",
    "\n",
    "    def show_images(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.train_X[i], cmap=plt.cm.binary)\n",
    "            plt.xlabel(self.label_names[self.train_Y[i]])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def draw_graph(history):\n",
    "    train_history = history.history[\"loss\"]\n",
    "    validation_history = history.history[\"val_loss\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Loss History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"LOSS Function\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"train_history.png\")\n",
    "\n",
    "    train_history = history.history[\"accuracy\"]\n",
    "    validation_history = history.history[\"val_accuracy\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Accuracy History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"accuracy_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataReader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÏñ¥ÏòµÎãàÎã§.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m dr \u001b[38;5;241m=\u001b[39m DataReader()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ï†úÏûëÌï©ÎãàÎã§.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     17\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataReader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "Date : 2020.07.24.\n",
    "\"\"\"\n",
    "from tensorflow import keras\n",
    "# import data_reader\n",
    "\n",
    "# Î™á ÏóêÌè¨ÌÅ¨ ÎßåÌÅº ÌïôÏäµÏùÑ ÏãúÌÇ¨ Í≤ÉÏù∏ÏßÄ Í≤∞Ï†ïÌï©ÎãàÎã§.\n",
    "EPOCHS = 20  # ÏòàÏ†ú Í∏∞Î≥∏Í∞íÏùÄ 20ÏûÖÎãàÎã§.\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÏñ¥ÏòµÎãàÎã§.\n",
    "dr = DataReader()\n",
    "print(dr.shape)\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ï†úÏûëÌï©ÎãàÎã§.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ïª¥ÌååÏùºÌï©ÎãàÎã§.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ ÌïôÏäµÏãúÌÇµÎãàÎã§.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# ÌïôÏäµ Í≤∞Í≥ºÎ•º Í∑∏ÎûòÌîÑÎ°ú Ï∂úÎ†•Ìï©ÎãàÎã§.\n",
    "DataReader.draw_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:43.490173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-14 15:17:44.548852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.549032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20480 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************ TRAINING START ************ \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:46.224690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-14 15:17:46.226085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83ac99f830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-14 15:17:46.226102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-08-14 15:17:46.228870: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-14 15:17:46.326553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.327999: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.334349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.335438: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.341473: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.342581: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.348260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.349280: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m************ TRAINING START ************ \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# ÌïôÏäµ Í≤∞Í≥ºÎ•º Í∑∏ÎûòÌîÑÎ°ú Ï∂úÎ†•Ìï©ÎãàÎã§.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# data_reader.draw_graph(history)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "\"\"\"\n",
    "# TensorFlow ÏÑ∏ÏÖò ÎòêÎäî Í∑∏ÎûòÌîÑÍ∞Ä Ï¢ÖÎ£åÎêú ÌõÑÏóê Î©îÎ™®Î¶¨ Ìï¥Ï†ú\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "# import pandas_datareader\n",
    "\n",
    "# Î™á ÏóêÌè¨ÌÅ¨ ÎßåÌÅº ÌïôÏäµÏùÑ ÏãúÌÇ¨ Í≤ÉÏù∏ÏßÄ Í≤∞Ï†ïÌï©ÎãàÎã§.\n",
    "EPOCHS = 100  # ÏòàÏ†ú Í∏∞Î≥∏Í∞íÏùÄ 20ÏûÖÎãàÎã§.\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞Î•º ÏùΩÏñ¥ÏòµÎãàÎã§.\n",
    "dr = DataReader()\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ï†úÏûëÌï©ÎãàÎã§.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ï†úÏûëÌï©ÎãàÎã§.\n",
    "model_temp = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ Ïª¥ÌååÏùºÌï©ÎãàÎã§.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Ïù∏Í≥µÏã†Í≤ΩÎßùÏùÑ ÌïôÏäµÏãúÌÇµÎãàÎã§.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# ÌïôÏäµ Í≤∞Í≥ºÎ•º Í∑∏ÎûòÌîÑÎ°ú Ï∂úÎ†•Ìï©ÎãàÎã§.\n",
    "# data_reader.draw_graph(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
