{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:37:39.314438: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-15 00:37:39.447471: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 설정 완료\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Python 버전📌 sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Pytorch 버전📌 2.0.1+cu117\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:torchvision 버전📌 0.15.2+cu117\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:ninja 버전📌 1.11.1\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Tensorflow 버전📌 2.13.0\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Torch GPU 가능여부📌 True\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Tensorflow GPU 가능여부📌 [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Click Version📌 8.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:37:41.369209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:37:41.370929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:37:41.371042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import inspect #디버깅용\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import ninja\n",
    "import click\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def time_stamp():\n",
    "    temp = r\"%Y-%m-%d %H:%M:%S\"\n",
    "    current_frame = inspect.currentframe()\n",
    "    tmp = f\"{time.strftime(temp, time.localtime(time.time()))}: [{inspect.getframeinfo(current_frame).filename}]:\"\n",
    "    return tmp\n",
    "\n",
    "def version_all():\n",
    "    print(f\"{time_stamp()}Python 버전📌 {sys.version_info}\")\n",
    "    print(f\"{time_stamp()}Pytorch 버전📌 {torch.__version__}\")\n",
    "    print(f\"{time_stamp()}torchvision 버전📌 {torchvision.__version__}\")\n",
    "    print(f\"{time_stamp()}ninja 버전📌 {ninja.__version__}\")\n",
    "    print(f\"{time_stamp()}Tensorflow 버전📌 {tf.__version__}\")\n",
    "    print(f\"{time_stamp()}Torch GPU 가능여부📌 {torch.torch.cuda.is_available()}\")\n",
    "    print(f\"{time_stamp()}Tensorflow GPU 가능여부📌 {tf.config.list_physical_devices('GPU')}\") # 텐서플로우 2.x버전\n",
    "    # print(f\"{time_stamp()}Tensorflow GPU 가능여부📌 {device_lib.list_local_devices()}\") # 텐서플로우 1.x버전\n",
    "    print(f\"{time_stamp()}Click Version📌 {click.__version__}\") # 텐서플로우 1.x버전\n",
    "    # print(f\"{time_stamp()}cudatoolkit Version📌 {cudatoolkit.__version__}\")\n",
    "    \n",
    "# GPU 사용 설정\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"GPU 설정 완료\")\n",
    "else:\n",
    "    print(\"GPU를 찾을 수 없습니다. CPU\")\n",
    "\n",
    "\n",
    "\n",
    "version_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU says hello.\n",
      "GPU says hello.\n"
     ]
    }
   ],
   "source": [
    "!nvcc test_nvcc.cu -o test_nvcc -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU 테스트\n",
    "* NVIDIA GPU 기준, 없다면 CPU로 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 생성 완료: (10000, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:29:01.339263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:01.339418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:01.339549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.183899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 00:29:02.184196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.168210</td>\n",
       "      <td>1.349127</td>\n",
       "      <td>-0.854028</td>\n",
       "      <td>0.409336</td>\n",
       "      <td>-1.835469</td>\n",
       "      <td>-0.457372</td>\n",
       "      <td>-0.177522</td>\n",
       "      <td>-1.992505</td>\n",
       "      <td>-0.948553</td>\n",
       "      <td>0.204065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098829</td>\n",
       "      <td>1.309362</td>\n",
       "      <td>-0.049714</td>\n",
       "      <td>0.957832</td>\n",
       "      <td>-0.362864</td>\n",
       "      <td>-1.079736</td>\n",
       "      <td>-0.189254</td>\n",
       "      <td>-1.735668</td>\n",
       "      <td>-0.643880</td>\n",
       "      <td>0.876057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.527508</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>-1.452178</td>\n",
       "      <td>-0.980168</td>\n",
       "      <td>0.615059</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>1.167043</td>\n",
       "      <td>0.501811</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.273663</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.124370</td>\n",
       "      <td>-1.792743</td>\n",
       "      <td>0.609617</td>\n",
       "      <td>-0.258457</td>\n",
       "      <td>1.559166</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>-1.662147</td>\n",
       "      <td>0.273517</td>\n",
       "      <td>-1.621412</td>\n",
       "      <td>-0.146486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.633722</td>\n",
       "      <td>1.296109</td>\n",
       "      <td>-0.207300</td>\n",
       "      <td>-0.793437</td>\n",
       "      <td>-2.422495</td>\n",
       "      <td>-1.881656</td>\n",
       "      <td>0.437407</td>\n",
       "      <td>-0.255688</td>\n",
       "      <td>0.844338</td>\n",
       "      <td>-0.154614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775560</td>\n",
       "      <td>-1.047454</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>0.148610</td>\n",
       "      <td>0.740087</td>\n",
       "      <td>0.357440</td>\n",
       "      <td>-0.298153</td>\n",
       "      <td>-0.318864</td>\n",
       "      <td>1.260440</td>\n",
       "      <td>-0.683796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.280686</td>\n",
       "      <td>0.415247</td>\n",
       "      <td>-0.739178</td>\n",
       "      <td>-0.345417</td>\n",
       "      <td>-0.025223</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>1.718670</td>\n",
       "      <td>1.524854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>-0.644891</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>-1.402139</td>\n",
       "      <td>-1.041350</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>-1.634882</td>\n",
       "      <td>-0.495770</td>\n",
       "      <td>0.638223</td>\n",
       "      <td>0.324767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451490</td>\n",
       "      <td>-1.552419</td>\n",
       "      <td>-0.289710</td>\n",
       "      <td>-2.123409</td>\n",
       "      <td>-0.860684</td>\n",
       "      <td>-0.451715</td>\n",
       "      <td>-0.840873</td>\n",
       "      <td>-0.382034</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>-0.800094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119762</td>\n",
       "      <td>-0.137987</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>-0.392496</td>\n",
       "      <td>0.534535</td>\n",
       "      <td>-2.284220</td>\n",
       "      <td>0.329657</td>\n",
       "      <td>0.786446</td>\n",
       "      <td>-0.422670</td>\n",
       "      <td>0.491280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.137492</td>\n",
       "      <td>-0.732939</td>\n",
       "      <td>-0.098758</td>\n",
       "      <td>-0.622943</td>\n",
       "      <td>-0.148596</td>\n",
       "      <td>0.707118</td>\n",
       "      <td>-2.026706</td>\n",
       "      <td>-0.077256</td>\n",
       "      <td>2.255109</td>\n",
       "      <td>1.208460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370883</td>\n",
       "      <td>0.314363</td>\n",
       "      <td>-0.392097</td>\n",
       "      <td>-1.124625</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>-1.894038</td>\n",
       "      <td>1.277450</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>0.977295</td>\n",
       "      <td>1.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.089010</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>-1.143470</td>\n",
       "      <td>-0.764562</td>\n",
       "      <td>-0.736837</td>\n",
       "      <td>-0.756180</td>\n",
       "      <td>-0.127646</td>\n",
       "      <td>-0.605088</td>\n",
       "      <td>-0.201341</td>\n",
       "      <td>-0.234649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.642154</td>\n",
       "      <td>0.313740</td>\n",
       "      <td>-0.432525</td>\n",
       "      <td>0.877071</td>\n",
       "      <td>-0.072756</td>\n",
       "      <td>1.496763</td>\n",
       "      <td>-0.177777</td>\n",
       "      <td>-0.579893</td>\n",
       "      <td>0.443538</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.762238</td>\n",
       "      <td>1.117830</td>\n",
       "      <td>0.750831</td>\n",
       "      <td>-0.480774</td>\n",
       "      <td>0.832223</td>\n",
       "      <td>-0.460444</td>\n",
       "      <td>-0.175959</td>\n",
       "      <td>-1.175802</td>\n",
       "      <td>-1.449352</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113890</td>\n",
       "      <td>-1.899127</td>\n",
       "      <td>-0.590906</td>\n",
       "      <td>-1.743504</td>\n",
       "      <td>1.363686</td>\n",
       "      <td>-0.887074</td>\n",
       "      <td>-0.173570</td>\n",
       "      <td>-0.688762</td>\n",
       "      <td>-1.010124</td>\n",
       "      <td>1.574567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.296977</td>\n",
       "      <td>0.453343</td>\n",
       "      <td>0.262107</td>\n",
       "      <td>2.374428</td>\n",
       "      <td>-1.484497</td>\n",
       "      <td>0.465641</td>\n",
       "      <td>-0.946833</td>\n",
       "      <td>-1.821712</td>\n",
       "      <td>1.434103</td>\n",
       "      <td>0.973426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744837</td>\n",
       "      <td>-0.769551</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.553946</td>\n",
       "      <td>1.020677</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>-0.106784</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-1.326676</td>\n",
       "      <td>1.346978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.493387</td>\n",
       "      <td>1.039987</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.067250</td>\n",
       "      <td>0.721398</td>\n",
       "      <td>0.448012</td>\n",
       "      <td>-1.295159</td>\n",
       "      <td>-0.609628</td>\n",
       "      <td>-1.845586</td>\n",
       "      <td>0.086504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156308</td>\n",
       "      <td>-1.630621</td>\n",
       "      <td>0.602154</td>\n",
       "      <td>-1.753530</td>\n",
       "      <td>-2.100452</td>\n",
       "      <td>-0.653552</td>\n",
       "      <td>-0.127404</td>\n",
       "      <td>0.620792</td>\n",
       "      <td>-0.446445</td>\n",
       "      <td>-1.311399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -1.168210  1.349127 -0.854028  0.409336 -1.835469 -0.457372 -0.177522   \n",
       "1    -0.527508  0.270189 -1.452178 -0.980168  0.615059 -0.386152  1.167043   \n",
       "2    -0.633722  1.296109 -0.207300 -0.793437 -2.422495 -1.881656  0.437407   \n",
       "3    -1.280686  0.415247 -0.739178 -0.345417 -0.025223  0.353818  0.027967   \n",
       "4     0.451490 -1.552419 -0.289710 -2.123409 -0.860684 -0.451715 -0.840873   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.137492 -0.732939 -0.098758 -0.622943 -0.148596  0.707118 -2.026706   \n",
       "9996 -1.089010  0.013095 -1.143470 -0.764562 -0.736837 -0.756180 -0.127646   \n",
       "9997  0.762238  1.117830  0.750831 -0.480774  0.832223 -0.460444 -0.175959   \n",
       "9998  0.296977  0.453343  0.262107  2.374428 -1.484497  0.465641 -0.946833   \n",
       "9999 -1.493387  1.039987 -0.732265 -0.067250  0.721398  0.448012 -1.295159   \n",
       "\n",
       "           7         8         9    ...       990       991       992  \\\n",
       "0    -1.992505 -0.948553  0.204065  ...  0.098829  1.309362 -0.049714   \n",
       "1     0.501811  0.973875  0.273663  ... -1.124370 -1.792743  0.609617   \n",
       "2    -0.255688  0.844338 -0.154614  ...  0.775560 -1.047454  0.389252   \n",
       "3     0.064670  1.718670  1.524854  ...  0.784675 -0.644891  1.583382   \n",
       "4    -0.382034  0.097928 -0.800094  ... -0.119762 -0.137987  0.052948   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995 -0.077256  2.255109  1.208460  ... -0.370883  0.314363 -0.392097   \n",
       "9996 -0.605088 -0.201341 -0.234649  ... -0.642154  0.313740 -0.432525   \n",
       "9997 -1.175802 -1.449352  0.365101  ...  0.113890 -1.899127 -0.590906   \n",
       "9998 -1.821712  1.434103  0.973426  ...  0.744837 -0.769551  0.286042   \n",
       "9999 -0.609628 -1.845586  0.086504  ...  0.156308 -1.630621  0.602154   \n",
       "\n",
       "           993       994       995       996       997       998       999  \n",
       "0     0.957832 -0.362864 -1.079736 -0.189254 -1.735668 -0.643880  0.876057  \n",
       "1    -0.258457  1.559166  0.344502 -1.662147  0.273517 -1.621412 -0.146486  \n",
       "2     0.148610  0.740087  0.357440 -0.298153 -0.318864  1.260440 -0.683796  \n",
       "3    -1.402139 -1.041350  0.101074 -1.634882 -0.495770  0.638223  0.324767  \n",
       "4    -0.392496  0.534535 -2.284220  0.329657  0.786446 -0.422670  0.491280  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.124625  0.015628 -1.894038  1.277450 -0.069881  0.977295  1.016667  \n",
       "9996  0.877071 -0.072756  1.496763 -0.177777 -0.579893  0.443538  0.094340  \n",
       "9997 -1.743504  1.363686 -0.887074 -0.173570 -0.688762 -1.010124  1.574567  \n",
       "9998  0.553946  1.020677  0.017773 -0.106784  0.002583 -1.326676  1.346978  \n",
       "9999 -1.753530 -2.100452 -0.653552 -0.127404  0.620792 -0.446445 -1.311399  \n",
       "\n",
       "[10000 rows x 1000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트할 데이터 생성\n",
    "input_data = tf.random.normal((10000, 1000))\n",
    "print(f\"데이터 생성 완료: {input_data.shape}\")\n",
    "before_df = pd.DataFrame(input_data)\n",
    "before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 버전:2.13.0\n",
      "첫 번째 실행 (GPU 초기화)\n",
      "1000000 번의 연산을 수행하며 GPU 성능 테스트를 진행합니다.\n",
      "1000000 번의 연산을 완료하는 데 걸린 총 시간: 65.59 초\n",
      "한 번의 연산 평균 소요 시간: 0.0001 초\n"
     ]
    }
   ],
   "source": [
    "# 몇 번 학습할건지?\n",
    "num_iterations = 1000000\n",
    "\n",
    "\n",
    "print(f\"TensorFlow 버전:{tf.__version__}\")\n",
    "\n",
    "# 모델 정의 (간단한 덧셈 연산)\n",
    "def simple_model(input_data):\n",
    "    return tf.reduce_sum(input_data)\n",
    "\n",
    "# 첫 번째 실행 (GPU 초기화 등)\n",
    "print(\"첫 번째 실행 (GPU 초기화)\")\n",
    "with tf.device('/GPU:0'):\n",
    "    _ = simple_model(input_data)\n",
    "\n",
    "\n",
    "print(f\"{num_iterations} 번의 연산을 수행하며 GPU 성능 테스트를 진행합니다.\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    with tf.device('/GPU:0'):\n",
    "        _ = simple_model(input_data)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"{num_iterations} 번의 연산을 완료하는 데 걸린 총 시간: {elapsed_time:.2f} 초\")\n",
    "print(f\"한 번의 연산 평균 소요 시간: {elapsed_time / num_iterations:.4f} 초\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 멀티프로세싱 기능 추가\n",
    "* 참고: https://d-life93.tistory.com/m/429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-08-15 실험시작. 멀티프로세싱 forkserver 기능 추가 중... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "def predict_test(image, path, img_height=256, img_weight=256):\n",
    "    # 사용 가능한 GPU 체크\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "    # 사용 가능한 GPU가 존재 할 경우\n",
    "    if gpus:\n",
    "        try:\n",
    "            # 사용할 GPU number 부여\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "            # GPU 메모리를 전부 사용하지 않고 천천히 사용할 만큼만 상승 시킨다.\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        except Exception:\n",
    "            raise {Exception}\n",
    "\n",
    "    # 모델 불러오기\n",
    "    model = tf.keras.models.load_model(path)\n",
    "\n",
    "    # 이미지를 읽어온다.\n",
    "    img = tf.keras.preprocessing.image.load_img(image, target_size=(img_height, img_weight))\n",
    "    # 이미지를 array로 변환한다.\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # 이미지를 4차원으로 변환한다.\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    # 이미지를 예측한다.\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # 예측한 값을 반환한다.\n",
    "    predict = predictions[0][0]\n",
    "\n",
    "    result = { predict } \n",
    "    return result\n",
    "\n",
    "\n",
    "def multiprocessing_test():\n",
    "    # 멀티 프로세싱 설정을 한다. *반드시 force를 사용\n",
    "    mp.set_start_method('forkserver', force=True)\n",
    "\n",
    "    # Process Pool생성\n",
    "    p = mp.Pool()     \n",
    "\n",
    "    # predict_test를 실행 후 데이터를 반환\n",
    "    prediction = p.starmap(predict_test, [(image, path, 256, 256)])  \n",
    "\n",
    "    # machine learning으로 발생한 다량의 데이터를 garbage collect로 정리를 한다.\n",
    "    # 정리하지 않을 경우 메모리 부족으로 에러가 발생한다.\n",
    "    gc.collect()\n",
    "\n",
    "    return prediction \n",
    "\n",
    "multiprocessing_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그냥 단편적인 코드조각(Snippets)들.. 테스트용!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow의 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:39:34.501678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:34.501822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:34.501923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 00:39:35.853519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일 경로\n",
    "image_path = './test_img.jpg'\n",
    "\n",
    "# 이미지 파일 읽어오기\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image)\n",
    "\n",
    "# 이미지 크기 조정 (옵션)\n",
    "image = tf.image.resize(image, [224, 224])  # 원하는 크기로 조정\n",
    "\n",
    "# 이미지 전처리 (옵션)\n",
    "image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # 모델에 맞는 전처리 방식 사용\n",
    "\n",
    "# 이미지를 모델에 입력하기 위해 차원 확장\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# 불러온 이미지 사용\n",
    "print(image.shape)  # 이미지 형태 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch의 이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 이미지 파일 경로\n",
    "image_path = './test_img.jpg'\n",
    "\n",
    "# 이미지 변환을 위한 전처리 단계 정의\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # 이미지를 Tensor로 변환\n",
    "    transforms.Resize((224, 224)),         # 원하는 크기로 조정\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 정규화\n",
    "])\n",
    "\n",
    "# 이미지 불러오기 및 전처리 적용\n",
    "image = Image.open(image_path)\n",
    "image = preprocess(image)\n",
    "\n",
    "# 이미지를 모델에 입력하기 위해 차원 확장\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "# 불러온 이미지 사용\n",
    "print(image.shape)  # 이미지 형태 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 세션 또는 그래프가 종료된 후에 메모리 해제\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# GPU 메모리 제한 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=20480)]  # 4GB 메모리 할당\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "try:\n",
    "    from matplotlib import pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'matplotlib'])\n",
    "    try:\n",
    "        from matplotlib import pyplot as plt\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'numpy'])\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "# 데이터를 떠먹여 줄 클래스를 제작합니다.\n",
    "class DataReader:\n",
    "    def __init__(self):\n",
    "        self.label_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "        self.mnist = keras.datasets.mnist\n",
    "        (train_X, self.train_Y), (test_X, self.test_Y) = self.mnist.load_data()\n",
    "\n",
    "        self.train_X = np.asarray(train_X) / 255.0\n",
    "        self.test_X = np.asarray(test_X) / 255.0\n",
    "\n",
    "        # 데이터 읽기가 완료되었습니다.\n",
    "        # 읽어온 데이터의 정보를 출력합니다.\n",
    "        print(\"\\n\\nData Read Done!\")\n",
    "        print(\"Training X Size : \" + str(self.train_X.shape))\n",
    "        print(\"Training Y Size : \" + str(self.train_Y.shape))\n",
    "        print(\"Test X Size : \" + str(self.test_X.shape))\n",
    "        print(\"Test Y Size : \" + str(self.test_Y.shape) + '\\n\\n')\n",
    "\n",
    "    def show_images(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.train_X[i], cmap=plt.cm.binary)\n",
    "            plt.xlabel(self.label_names[self.train_Y[i]])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def draw_graph(history):\n",
    "    train_history = history.history[\"loss\"]\n",
    "    validation_history = history.history[\"val_loss\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Loss History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"LOSS Function\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"train_history.png\")\n",
    "\n",
    "    train_history = history.history[\"accuracy\"]\n",
    "    validation_history = history.history[\"val_accuracy\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Accuracy History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"accuracy_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataReader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 데이터를 읽어옵니다.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m dr \u001b[38;5;241m=\u001b[39m DataReader()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 인공신경망을 제작합니다.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     17\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataReader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "Date : 2020.07.24.\n",
    "\"\"\"\n",
    "from tensorflow import keras\n",
    "# import data_reader\n",
    "\n",
    "# 몇 에포크 만큼 학습을 시킬 것인지 결정합니다.\n",
    "EPOCHS = 20  # 예제 기본값은 20입니다.\n",
    "\n",
    "# 데이터를 읽어옵니다.\n",
    "dr = DataReader()\n",
    "print(dr.shape)\n",
    "\n",
    "# 인공신경망을 제작합니다.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 인공신경망을 컴파일합니다.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# 인공신경망을 학습시킵니다.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# 학습 결과를 그래프로 출력합니다.\n",
    "DataReader.draw_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:43.490173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-14 15:17:44.548852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.549032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20480 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************ TRAINING START ************ \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:46.224690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-14 15:17:46.226085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83ac99f830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-14 15:17:46.226102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-08-14 15:17:46.228870: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-14 15:17:46.326553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.327999: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.334349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.335438: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.341473: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.342581: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.348260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.349280: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m************ TRAINING START ************ \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# 학습 결과를 그래프로 출력합니다.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# data_reader.draw_graph(history)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "\"\"\"\n",
    "# TensorFlow 세션 또는 그래프가 종료된 후에 메모리 해제\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "# import pandas_datareader\n",
    "\n",
    "# 몇 에포크 만큼 학습을 시킬 것인지 결정합니다.\n",
    "EPOCHS = 100  # 예제 기본값은 20입니다.\n",
    "\n",
    "# 데이터를 읽어옵니다.\n",
    "dr = DataReader()\n",
    "\n",
    "# 인공신경망을 제작합니다.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 인공신경망을 제작합니다.\n",
    "model_temp = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 인공신경망을 컴파일합니다.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# 인공신경망을 학습시킵니다.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# 학습 결과를 그래프로 출력합니다.\n",
    "# data_reader.draw_graph(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
