{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:37:39.314438: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-15 00:37:39.447471: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ì„¤ì • ì™„ë£Œ\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Python ë²„ì „ðŸ“Œ sys.version_info(major=3, minor=8, micro=10, releaselevel='final', serial=0)\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Pytorch ë²„ì „ðŸ“Œ 2.0.1+cu117\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:torchvision ë²„ì „ðŸ“Œ 0.15.2+cu117\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:ninja ë²„ì „ðŸ“Œ 1.11.1\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Tensorflow ë²„ì „ðŸ“Œ 2.13.0\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Torch GPU ê°€ëŠ¥ì—¬ë¶€ðŸ“Œ True\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Tensorflow GPU ê°€ëŠ¥ì—¬ë¶€ðŸ“Œ [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-08-15 00:37:41: [/tmp/ipykernel_22/1020039573.py]:Click VersionðŸ“Œ 8.1.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:37:41.369209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:37:41.370929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:37:41.371042: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sys\n",
    "import inspect #ë””ë²„ê¹…ìš©\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import torchvision\n",
    "import ninja\n",
    "import click\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def time_stamp():\n",
    "    temp = r\"%Y-%m-%d %H:%M:%S\"\n",
    "    current_frame = inspect.currentframe()\n",
    "    tmp = f\"{time.strftime(temp, time.localtime(time.time()))}: [{inspect.getframeinfo(current_frame).filename}]:\"\n",
    "    return tmp\n",
    "\n",
    "def version_all():\n",
    "    print(f\"{time_stamp()}Python ë²„ì „ðŸ“Œ {sys.version_info}\")\n",
    "    print(f\"{time_stamp()}Pytorch ë²„ì „ðŸ“Œ {torch.__version__}\")\n",
    "    print(f\"{time_stamp()}torchvision ë²„ì „ðŸ“Œ {torchvision.__version__}\")\n",
    "    print(f\"{time_stamp()}ninja ë²„ì „ðŸ“Œ {ninja.__version__}\")\n",
    "    print(f\"{time_stamp()}Tensorflow ë²„ì „ðŸ“Œ {tf.__version__}\")\n",
    "    print(f\"{time_stamp()}Torch GPU ê°€ëŠ¥ì—¬ë¶€ðŸ“Œ {torch.torch.cuda.is_available()}\")\n",
    "    print(f\"{time_stamp()}Tensorflow GPU ê°€ëŠ¥ì—¬ë¶€ðŸ“Œ {tf.config.list_physical_devices('GPU')}\") # í…ì„œí”Œë¡œìš° 2.xë²„ì „\n",
    "    # print(f\"{time_stamp()}Tensorflow GPU ê°€ëŠ¥ì—¬ë¶€ðŸ“Œ {device_lib.list_local_devices()}\") # í…ì„œí”Œë¡œìš° 1.xë²„ì „\n",
    "    print(f\"{time_stamp()}Click VersionðŸ“Œ {click.__version__}\") # í…ì„œí”Œë¡œìš° 1.xë²„ì „\n",
    "    # print(f\"{time_stamp()}cudatoolkit VersionðŸ“Œ {cudatoolkit.__version__}\")\n",
    "    \n",
    "# GPU ì‚¬ìš© ì„¤ì •\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(\"GPU ì„¤ì • ì™„ë£Œ\")\n",
    "else:\n",
    "    print(\"GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU\")\n",
    "\n",
    "\n",
    "\n",
    "version_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU says hello.\n",
      "GPU says hello.\n"
     ]
    }
   ],
   "source": [
    "!nvcc test_nvcc.cu -o test_nvcc -run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU í…ŒìŠ¤íŠ¸\n",
    "* NVIDIA GPU ê¸°ì¤€, ì—†ë‹¤ë©´ CPUë¡œ í…ŒìŠ¤íŠ¸ ì§„í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒì„± ì™„ë£Œ: (10000, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:29:01.339263: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:01.339418: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:01.339549: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.183899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184068: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 00:29:02.184196: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:29:02.184227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.168210</td>\n",
       "      <td>1.349127</td>\n",
       "      <td>-0.854028</td>\n",
       "      <td>0.409336</td>\n",
       "      <td>-1.835469</td>\n",
       "      <td>-0.457372</td>\n",
       "      <td>-0.177522</td>\n",
       "      <td>-1.992505</td>\n",
       "      <td>-0.948553</td>\n",
       "      <td>0.204065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098829</td>\n",
       "      <td>1.309362</td>\n",
       "      <td>-0.049714</td>\n",
       "      <td>0.957832</td>\n",
       "      <td>-0.362864</td>\n",
       "      <td>-1.079736</td>\n",
       "      <td>-0.189254</td>\n",
       "      <td>-1.735668</td>\n",
       "      <td>-0.643880</td>\n",
       "      <td>0.876057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.527508</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>-1.452178</td>\n",
       "      <td>-0.980168</td>\n",
       "      <td>0.615059</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>1.167043</td>\n",
       "      <td>0.501811</td>\n",
       "      <td>0.973875</td>\n",
       "      <td>0.273663</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.124370</td>\n",
       "      <td>-1.792743</td>\n",
       "      <td>0.609617</td>\n",
       "      <td>-0.258457</td>\n",
       "      <td>1.559166</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>-1.662147</td>\n",
       "      <td>0.273517</td>\n",
       "      <td>-1.621412</td>\n",
       "      <td>-0.146486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.633722</td>\n",
       "      <td>1.296109</td>\n",
       "      <td>-0.207300</td>\n",
       "      <td>-0.793437</td>\n",
       "      <td>-2.422495</td>\n",
       "      <td>-1.881656</td>\n",
       "      <td>0.437407</td>\n",
       "      <td>-0.255688</td>\n",
       "      <td>0.844338</td>\n",
       "      <td>-0.154614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.775560</td>\n",
       "      <td>-1.047454</td>\n",
       "      <td>0.389252</td>\n",
       "      <td>0.148610</td>\n",
       "      <td>0.740087</td>\n",
       "      <td>0.357440</td>\n",
       "      <td>-0.298153</td>\n",
       "      <td>-0.318864</td>\n",
       "      <td>1.260440</td>\n",
       "      <td>-0.683796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.280686</td>\n",
       "      <td>0.415247</td>\n",
       "      <td>-0.739178</td>\n",
       "      <td>-0.345417</td>\n",
       "      <td>-0.025223</td>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.027967</td>\n",
       "      <td>0.064670</td>\n",
       "      <td>1.718670</td>\n",
       "      <td>1.524854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>-0.644891</td>\n",
       "      <td>1.583382</td>\n",
       "      <td>-1.402139</td>\n",
       "      <td>-1.041350</td>\n",
       "      <td>0.101074</td>\n",
       "      <td>-1.634882</td>\n",
       "      <td>-0.495770</td>\n",
       "      <td>0.638223</td>\n",
       "      <td>0.324767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.451490</td>\n",
       "      <td>-1.552419</td>\n",
       "      <td>-0.289710</td>\n",
       "      <td>-2.123409</td>\n",
       "      <td>-0.860684</td>\n",
       "      <td>-0.451715</td>\n",
       "      <td>-0.840873</td>\n",
       "      <td>-0.382034</td>\n",
       "      <td>0.097928</td>\n",
       "      <td>-0.800094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.119762</td>\n",
       "      <td>-0.137987</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>-0.392496</td>\n",
       "      <td>0.534535</td>\n",
       "      <td>-2.284220</td>\n",
       "      <td>0.329657</td>\n",
       "      <td>0.786446</td>\n",
       "      <td>-0.422670</td>\n",
       "      <td>0.491280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>-0.137492</td>\n",
       "      <td>-0.732939</td>\n",
       "      <td>-0.098758</td>\n",
       "      <td>-0.622943</td>\n",
       "      <td>-0.148596</td>\n",
       "      <td>0.707118</td>\n",
       "      <td>-2.026706</td>\n",
       "      <td>-0.077256</td>\n",
       "      <td>2.255109</td>\n",
       "      <td>1.208460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370883</td>\n",
       "      <td>0.314363</td>\n",
       "      <td>-0.392097</td>\n",
       "      <td>-1.124625</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>-1.894038</td>\n",
       "      <td>1.277450</td>\n",
       "      <td>-0.069881</td>\n",
       "      <td>0.977295</td>\n",
       "      <td>1.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.089010</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>-1.143470</td>\n",
       "      <td>-0.764562</td>\n",
       "      <td>-0.736837</td>\n",
       "      <td>-0.756180</td>\n",
       "      <td>-0.127646</td>\n",
       "      <td>-0.605088</td>\n",
       "      <td>-0.201341</td>\n",
       "      <td>-0.234649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.642154</td>\n",
       "      <td>0.313740</td>\n",
       "      <td>-0.432525</td>\n",
       "      <td>0.877071</td>\n",
       "      <td>-0.072756</td>\n",
       "      <td>1.496763</td>\n",
       "      <td>-0.177777</td>\n",
       "      <td>-0.579893</td>\n",
       "      <td>0.443538</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.762238</td>\n",
       "      <td>1.117830</td>\n",
       "      <td>0.750831</td>\n",
       "      <td>-0.480774</td>\n",
       "      <td>0.832223</td>\n",
       "      <td>-0.460444</td>\n",
       "      <td>-0.175959</td>\n",
       "      <td>-1.175802</td>\n",
       "      <td>-1.449352</td>\n",
       "      <td>0.365101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113890</td>\n",
       "      <td>-1.899127</td>\n",
       "      <td>-0.590906</td>\n",
       "      <td>-1.743504</td>\n",
       "      <td>1.363686</td>\n",
       "      <td>-0.887074</td>\n",
       "      <td>-0.173570</td>\n",
       "      <td>-0.688762</td>\n",
       "      <td>-1.010124</td>\n",
       "      <td>1.574567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.296977</td>\n",
       "      <td>0.453343</td>\n",
       "      <td>0.262107</td>\n",
       "      <td>2.374428</td>\n",
       "      <td>-1.484497</td>\n",
       "      <td>0.465641</td>\n",
       "      <td>-0.946833</td>\n",
       "      <td>-1.821712</td>\n",
       "      <td>1.434103</td>\n",
       "      <td>0.973426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744837</td>\n",
       "      <td>-0.769551</td>\n",
       "      <td>0.286042</td>\n",
       "      <td>0.553946</td>\n",
       "      <td>1.020677</td>\n",
       "      <td>0.017773</td>\n",
       "      <td>-0.106784</td>\n",
       "      <td>0.002583</td>\n",
       "      <td>-1.326676</td>\n",
       "      <td>1.346978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>-1.493387</td>\n",
       "      <td>1.039987</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.067250</td>\n",
       "      <td>0.721398</td>\n",
       "      <td>0.448012</td>\n",
       "      <td>-1.295159</td>\n",
       "      <td>-0.609628</td>\n",
       "      <td>-1.845586</td>\n",
       "      <td>0.086504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156308</td>\n",
       "      <td>-1.630621</td>\n",
       "      <td>0.602154</td>\n",
       "      <td>-1.753530</td>\n",
       "      <td>-2.100452</td>\n",
       "      <td>-0.653552</td>\n",
       "      <td>-0.127404</td>\n",
       "      <td>0.620792</td>\n",
       "      <td>-0.446445</td>\n",
       "      <td>-1.311399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0    -1.168210  1.349127 -0.854028  0.409336 -1.835469 -0.457372 -0.177522   \n",
       "1    -0.527508  0.270189 -1.452178 -0.980168  0.615059 -0.386152  1.167043   \n",
       "2    -0.633722  1.296109 -0.207300 -0.793437 -2.422495 -1.881656  0.437407   \n",
       "3    -1.280686  0.415247 -0.739178 -0.345417 -0.025223  0.353818  0.027967   \n",
       "4     0.451490 -1.552419 -0.289710 -2.123409 -0.860684 -0.451715 -0.840873   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995 -0.137492 -0.732939 -0.098758 -0.622943 -0.148596  0.707118 -2.026706   \n",
       "9996 -1.089010  0.013095 -1.143470 -0.764562 -0.736837 -0.756180 -0.127646   \n",
       "9997  0.762238  1.117830  0.750831 -0.480774  0.832223 -0.460444 -0.175959   \n",
       "9998  0.296977  0.453343  0.262107  2.374428 -1.484497  0.465641 -0.946833   \n",
       "9999 -1.493387  1.039987 -0.732265 -0.067250  0.721398  0.448012 -1.295159   \n",
       "\n",
       "           7         8         9    ...       990       991       992  \\\n",
       "0    -1.992505 -0.948553  0.204065  ...  0.098829  1.309362 -0.049714   \n",
       "1     0.501811  0.973875  0.273663  ... -1.124370 -1.792743  0.609617   \n",
       "2    -0.255688  0.844338 -0.154614  ...  0.775560 -1.047454  0.389252   \n",
       "3     0.064670  1.718670  1.524854  ...  0.784675 -0.644891  1.583382   \n",
       "4    -0.382034  0.097928 -0.800094  ... -0.119762 -0.137987  0.052948   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995 -0.077256  2.255109  1.208460  ... -0.370883  0.314363 -0.392097   \n",
       "9996 -0.605088 -0.201341 -0.234649  ... -0.642154  0.313740 -0.432525   \n",
       "9997 -1.175802 -1.449352  0.365101  ...  0.113890 -1.899127 -0.590906   \n",
       "9998 -1.821712  1.434103  0.973426  ...  0.744837 -0.769551  0.286042   \n",
       "9999 -0.609628 -1.845586  0.086504  ...  0.156308 -1.630621  0.602154   \n",
       "\n",
       "           993       994       995       996       997       998       999  \n",
       "0     0.957832 -0.362864 -1.079736 -0.189254 -1.735668 -0.643880  0.876057  \n",
       "1    -0.258457  1.559166  0.344502 -1.662147  0.273517 -1.621412 -0.146486  \n",
       "2     0.148610  0.740087  0.357440 -0.298153 -0.318864  1.260440 -0.683796  \n",
       "3    -1.402139 -1.041350  0.101074 -1.634882 -0.495770  0.638223  0.324767  \n",
       "4    -0.392496  0.534535 -2.284220  0.329657  0.786446 -0.422670  0.491280  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "9995 -1.124625  0.015628 -1.894038  1.277450 -0.069881  0.977295  1.016667  \n",
       "9996  0.877071 -0.072756  1.496763 -0.177777 -0.579893  0.443538  0.094340  \n",
       "9997 -1.743504  1.363686 -0.887074 -0.173570 -0.688762 -1.010124  1.574567  \n",
       "9998  0.553946  1.020677  0.017773 -0.106784  0.002583 -1.326676  1.346978  \n",
       "9999 -1.753530 -2.100452 -0.653552 -0.127404  0.620792 -0.446445 -1.311399  \n",
       "\n",
       "[10000 rows x 1000 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸í•  ë°ì´í„° ìƒì„±\n",
    "input_data = tf.random.normal((10000, 1000))\n",
    "print(f\"ë°ì´í„° ìƒì„± ì™„ë£Œ: {input_data.shape}\")\n",
    "before_df = pd.DataFrame(input_data)\n",
    "before_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow ë²„ì „:2.13.0\n",
      "ì²« ë²ˆì§¸ ì‹¤í–‰ (GPU ì´ˆê¸°í™”)\n",
      "1000000 ë²ˆì˜ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©° GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
      "1000000 ë²ˆì˜ ì—°ì‚°ì„ ì™„ë£Œí•˜ëŠ” ë° ê±¸ë¦° ì´ ì‹œê°„: 65.59 ì´ˆ\n",
      "í•œ ë²ˆì˜ ì—°ì‚° í‰ê·  ì†Œìš” ì‹œê°„: 0.0001 ì´ˆ\n"
     ]
    }
   ],
   "source": [
    "# ëª‡ ë²ˆ í•™ìŠµí• ê±´ì§€?\n",
    "num_iterations = 1000000\n",
    "\n",
    "\n",
    "print(f\"TensorFlow ë²„ì „:{tf.__version__}\")\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜ (ê°„ë‹¨í•œ ë§ì…ˆ ì—°ì‚°)\n",
    "def simple_model(input_data):\n",
    "    return tf.reduce_sum(input_data)\n",
    "\n",
    "# ì²« ë²ˆì§¸ ì‹¤í–‰ (GPU ì´ˆê¸°í™” ë“±)\n",
    "print(\"ì²« ë²ˆì§¸ ì‹¤í–‰ (GPU ì´ˆê¸°í™”)\")\n",
    "with tf.device('/GPU:0'):\n",
    "    _ = simple_model(input_data)\n",
    "\n",
    "\n",
    "print(f\"{num_iterations} ë²ˆì˜ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ë©° GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "    with tf.device('/GPU:0'):\n",
    "        _ = simple_model(input_data)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"{num_iterations} ë²ˆì˜ ì—°ì‚°ì„ ì™„ë£Œí•˜ëŠ” ë° ê±¸ë¦° ì´ ì‹œê°„: {elapsed_time:.2f} ì´ˆ\")\n",
    "print(f\"í•œ ë²ˆì˜ ì—°ì‚° í‰ê·  ì†Œìš” ì‹œê°„: {elapsed_time / num_iterations:.4f} ì´ˆ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë©€í‹°í”„ë¡œì„¸ì‹± ê¸°ëŠ¥ ì¶”ê°€\n",
    "* ì°¸ê³ : https://d-life93.tistory.com/m/429"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2023-08-15 ì‹¤í—˜ì‹œìž‘. ë©€í‹°í”„ë¡œì„¸ì‹± forkserver ê¸°ëŠ¥ ì¶”ê°€ ì¤‘... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "def predict_test(image, path, img_height=256, img_weight=256):\n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ GPU ì²´í¬\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "    # ì‚¬ìš© ê°€ëŠ¥í•œ GPUê°€ ì¡´ìž¬ í•  ê²½ìš°\n",
    "    if gpus:\n",
    "        try:\n",
    "            # ì‚¬ìš©í•  GPU number ë¶€ì—¬\n",
    "            tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "            # GPU ë©”ëª¨ë¦¬ë¥¼ ì „ë¶€ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì²œì²œížˆ ì‚¬ìš©í•  ë§Œí¼ë§Œ ìƒìŠ¹ ì‹œí‚¨ë‹¤.\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        except Exception:\n",
    "            raise {Exception}\n",
    "\n",
    "    # ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    model = tf.keras.models.load_model(path)\n",
    "\n",
    "    # ì´ë¯¸ì§€ë¥¼ ì½ì–´ì˜¨ë‹¤.\n",
    "    img = tf.keras.preprocessing.image.load_img(image, target_size=(img_height, img_weight))\n",
    "    # ì´ë¯¸ì§€ë¥¼ arrayë¡œ ë³€í™˜í•œë‹¤.\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    # ì´ë¯¸ì§€ë¥¼ 4ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•œë‹¤.\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    # ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•œë‹¤.\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    # ì˜ˆì¸¡í•œ ê°’ì„ ë°˜í™˜í•œë‹¤.\n",
    "    predict = predictions[0][0]\n",
    "\n",
    "    result = { predict } \n",
    "    return result\n",
    "\n",
    "\n",
    "def multiprocessing_test():\n",
    "    # ë©€í‹° í”„ë¡œì„¸ì‹± ì„¤ì •ì„ í•œë‹¤. *ë°˜ë“œì‹œ forceë¥¼ ì‚¬ìš©\n",
    "    mp.set_start_method('forkserver', force=True)\n",
    "\n",
    "    # Process Poolìƒì„±\n",
    "    p = mp.Pool()     \n",
    "\n",
    "    # predict_testë¥¼ ì‹¤í–‰ í›„ ë°ì´í„°ë¥¼ ë°˜í™˜\n",
    "    prediction = p.starmap(predict_test, [(image, path, 256, 256)])  \n",
    "\n",
    "    # machine learningìœ¼ë¡œ ë°œìƒí•œ ë‹¤ëŸ‰ì˜ ë°ì´í„°ë¥¼ garbage collectë¡œ ì •ë¦¬ë¥¼ í•œë‹¤.\n",
    "    # ì •ë¦¬í•˜ì§€ ì•Šì„ ê²½ìš° ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤.\n",
    "    gc.collect()\n",
    "\n",
    "    return prediction \n",
    "\n",
    "multiprocessing_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê·¸ëƒ¥ ë‹¨íŽ¸ì ì¸ ì½”ë“œì¡°ê°(Snippets)ë“¤.. í…ŒìŠ¤íŠ¸ìš©!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflowì˜ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 00:39:34.501678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:34.501822: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:34.501923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853200: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 00:39:35.853519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-15 00:39:35.853564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21181 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "image_path = './test_img.jpg'\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ì½ì–´ì˜¤ê¸°\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_image(image)\n",
    "\n",
    "# ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (ì˜µì…˜)\n",
    "image = tf.image.resize(image, [224, 224])  # ì›í•˜ëŠ” í¬ê¸°ë¡œ ì¡°ì •\n",
    "\n",
    "# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì˜µì…˜)\n",
    "image = tf.keras.applications.mobilenet_v2.preprocess_input(image)  # ëª¨ë¸ì— ë§žëŠ” ì „ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš©\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ìž…ë ¥í•˜ê¸° ìœ„í•´ ì°¨ì› í™•ìž¥\n",
    "image = tf.expand_dims(image, axis=0)\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ ì‚¬ìš©\n",
    "print(image.shape)  # ì´ë¯¸ì§€ í˜•íƒœ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchì˜ ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "image_path = './test_img.jpg'\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³€í™˜ì„ ìœ„í•œ ì „ì²˜ë¦¬ ë‹¨ê³„ ì •ì˜\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # ì´ë¯¸ì§€ë¥¼ Tensorë¡œ ë³€í™˜\n",
    "    transforms.Resize((224, 224)),         # ì›í•˜ëŠ” í¬ê¸°ë¡œ ì¡°ì •\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # ì •ê·œí™”\n",
    "])\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬ ì ìš©\n",
    "image = Image.open(image_path)\n",
    "image = preprocess(image)\n",
    "\n",
    "# ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ìž…ë ¥í•˜ê¸° ìœ„í•´ ì°¨ì› í™•ìž¥\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "# ë¶ˆëŸ¬ì˜¨ ì´ë¯¸ì§€ ì‚¬ìš©\n",
    "print(image.shape)  # ì´ë¯¸ì§€ í˜•íƒœ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow ì„¸ì…˜ ë˜ëŠ” ê·¸ëž˜í”„ê°€ ì¢…ë£Œëœ í›„ì— ë©”ëª¨ë¦¬ í•´ì œ\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=20480)]  # 4GB ë©”ëª¨ë¦¬ í• ë‹¹\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas-datareader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import time\n",
    "try:\n",
    "    from matplotlib import pyplot as plt\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'matplotlib'])\n",
    "    try:\n",
    "        from matplotlib import pyplot as plt\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "except ModuleNotFoundError:\n",
    "    import pip\n",
    "    pip.main(['install', 'numpy'])\n",
    "    try:\n",
    "        import numpy as np\n",
    "    except ModuleNotFoundError:\n",
    "        time.sleep(2)\n",
    "        import numpy as np\n",
    "\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ë– ë¨¹ì—¬ ì¤„ í´ëž˜ìŠ¤ë¥¼ ì œìž‘í•©ë‹ˆë‹¤.\n",
    "class DataReader:\n",
    "    def __init__(self):\n",
    "        self.label_names = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "        self.mnist = keras.datasets.mnist\n",
    "        (train_X, self.train_Y), (test_X, self.test_Y) = self.mnist.load_data()\n",
    "\n",
    "        self.train_X = np.asarray(train_X) / 255.0\n",
    "        self.test_X = np.asarray(test_X) / 255.0\n",
    "\n",
    "        # ë°ì´í„° ì½ê¸°ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "        # ì½ì–´ì˜¨ ë°ì´í„°ì˜ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "        print(\"\\n\\nData Read Done!\")\n",
    "        print(\"Training X Size : \" + str(self.train_X.shape))\n",
    "        print(\"Training Y Size : \" + str(self.train_Y.shape))\n",
    "        print(\"Test X Size : \" + str(self.test_X.shape))\n",
    "        print(\"Test Y Size : \" + str(self.test_Y.shape) + '\\n\\n')\n",
    "\n",
    "    def show_images(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(self.train_X[i], cmap=plt.cm.binary)\n",
    "            plt.xlabel(self.label_names[self.train_Y[i]])\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def draw_graph(history):\n",
    "    train_history = history.history[\"loss\"]\n",
    "    validation_history = history.history[\"val_loss\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Loss History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"LOSS Function\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"train_history.png\")\n",
    "\n",
    "    train_history = history.history[\"accuracy\"]\n",
    "    validation_history = history.history[\"val_accuracy\"]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    plt.title(\"Accuracy History\")\n",
    "    plt.xlabel(\"EPOCH\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.plot(train_history, \"red\")\n",
    "    plt.plot(validation_history, 'blue')\n",
    "    fig.savefig(\"accuracy_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataReader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m dr \u001b[38;5;241m=\u001b[39m DataReader()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# ì¸ê³µì‹ ê²½ë§ì„ ì œìž‘í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m     17\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)),\n\u001b[1;32m     18\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     19\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m ])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataReader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "Date : 2020.07.24.\n",
    "\"\"\"\n",
    "from tensorflow import keras\n",
    "# import data_reader\n",
    "\n",
    "# ëª‡ ì—í¬í¬ ë§Œí¼ í•™ìŠµì„ ì‹œí‚¬ ê²ƒì¸ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "EPOCHS = 20  # ì˜ˆì œ ê¸°ë³¸ê°’ì€ 20ìž…ë‹ˆë‹¤.\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "dr = DataReader()\n",
    "print(dr.shape)\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ ì œìž‘í•©ë‹ˆë‹¤.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ ì»´íŒŒì¼í•©ë‹ˆë‹¤.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ë¥¼ ê·¸ëž˜í”„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "DataReader.draw_graph(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data Read Done!\n",
      "Training X Size : (60000, 28, 28)\n",
      "Training Y Size : (60000,)\n",
      "Test X Size : (10000, 28, 28)\n",
      "Test Y Size : (10000,)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:43.490173: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490322: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:43.490430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548559: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1726] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-14 15:17:44.548852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.548999: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-14 15:17:44.549032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20480 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "************ TRAINING START ************ \n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:17:46.224690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-14 15:17:46.226085: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f83ac99f830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-14 15:17:46.226102: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2023-08-14 15:17:46.228870: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-14 15:17:46.326553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.327999: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.334349: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.335438: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.341473: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.342581: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n",
      "2023-08-14 15:17:46.348260: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:425] Loaded runtime CuDNN library: 8.5.0 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-08-14 15:17:46.349280: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m************ TRAINING START ************ \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_Y\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# í•™ìŠµ ê²°ê³¼ë¥¼ ê·¸ëž˜í”„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# data_reader.draw_graph(history)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Graph execution error:\n\nDetected at node 'Adam/StatefulPartitionedCall_2' defined at (most recent call last):\n    File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_809/2643362658.py\", line 48, in <module>\n      history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'Adam/StatefulPartitionedCall_2'\nDNN library initialization failed. Look at the errors above for more details.\n\t [[{{node Adam/StatefulPartitionedCall_2}}]] [Op:__inference_train_function_732]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Author : Byunghyun Ban\n",
    "\"\"\"\n",
    "# TensorFlow ì„¸ì…˜ ë˜ëŠ” ê·¸ëž˜í”„ê°€ ì¢…ë£Œëœ í›„ì— ë©”ëª¨ë¦¬ í•´ì œ\n",
    "tf.keras.backend.clear_session()\n",
    "from tensorflow import keras\n",
    "# import pandas_datareader\n",
    "\n",
    "# ëª‡ ì—í¬í¬ ë§Œí¼ í•™ìŠµì„ ì‹œí‚¬ ê²ƒì¸ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "EPOCHS = 100  # ì˜ˆì œ ê¸°ë³¸ê°’ì€ 20ìž…ë‹ˆë‹¤.\n",
    "\n",
    "# ë°ì´í„°ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "dr = DataReader()\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ ì œìž‘í•©ë‹ˆë‹¤.\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ ì œìž‘í•©ë‹ˆë‹¤.\n",
    "model_temp = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(rate=0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ ì»´íŒŒì¼í•©ë‹ˆë‹¤.\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],\n",
    "              loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# ì¸ê³µì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.\n",
    "print(\"\\n\\n************ TRAINING START ************ \")\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
    "                    validation_data=(dr.test_X, dr.test_Y),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# í•™ìŠµ ê²°ê³¼ë¥¼ ê·¸ëž˜í”„ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "# data_reader.draw_graph(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
